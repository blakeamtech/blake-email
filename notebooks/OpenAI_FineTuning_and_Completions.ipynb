{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVyaI77fzH7S",
        "outputId": "679fc59d-710f-424c-df5a-96082107aa0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.35.13)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OqP28vln9tq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('https://raw.githubusercontent.com/blakeamtech/blake-email/main/synthetic_examples.csv', index_col=0)\n",
        "dataset.dropna(inplace=True)\n",
        "\n",
        "# Prepare JSON data for fine-tuning\n",
        "json_data = [\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"Blake is a friendly machine learning engineer.\"},\n",
        "            {\"role\": \"user\", \"content\": email},\n",
        "            {\"role\": \"assistant\", \"content\": response}\n",
        "        ]\n",
        "    }\n",
        "    for email, response in dataset.to_numpy()\n",
        "]\n",
        "\n",
        "# Write JSON data to a file\n",
        "with open('data.jsonl', 'w') as file:\n",
        "    for item in json_data:\n",
        "        file.write(json.dumps(item) + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the OpenAI client\n",
        "client = OpenAI(api_key=os.getenv('OPEN_AI_KEY'))\n",
        "\n",
        "# Upload the file for fine-tuning\n",
        "training_file = client.files.create(\n",
        "    file=open(\"data.jsonl\", \"rb\"),\n",
        "    purpose=\"fine-tune\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BS4tmInXy1ql",
        "outputId": "aec1256a-07fd-471c-f81f-ef9f26c34a27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FileObject(id='file-hPPgX3TIYGwcg070MhKCQuk4', bytes=603303, created_at=1720634775, filename='data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a fine-tuning job\n",
        "fine_tune_job = client.fine_tuning.jobs.create(\n",
        "    training_file=training_file.id,\n",
        "    model=\"gpt-3.5-turbo\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2M-0J-0NxPuF",
        "outputId": "1f196c97-8fc6-4cc8-dbc8-81cab71a4da6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-hrOzszoQdx8csV0LD5kP08bO', created_at=1720634798, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-LHmbltGNZrEjXbpsVBe9nMtw', result_files=[], seed=895097390, status='validating_files', trained_tokens=None, training_file='file-hPPgX3TIYGwcg070MhKCQuk4', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the model has been fine-tuned, using it for chat completion\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"ft:gpt-3.5-turbo-0125:techograms::9jWj2X7v\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Blake is a friendly machine learning engineer.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Hi Blake, tell something cool about AI.\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Print the assistant's response\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ov-35Z_hBGbz",
        "outputId": "7bb6aa8e-5574-49b0-e59d-42e8a59d38f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI is transforming the future of healthcare through its ability to analyze complex medical data with speed and accuracy. This has the potential to revolutionize diagnostics, personalized treatments, and preventative care. Exciting times ahead!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}